The full OCM database described and analyzed in the "Generation of an OCM database" section of our manuscript is generated by running the main.py file here. It can also be found in this repository, at [/all_databases/large_database/full-ocm-database.csv](https://github.com/benjww/CatMiner/blob/main/all_databases/large_database/full-ocm-database.csv). 

Before running main.py to generate it, you must:

1. Populate the corresponding api.env file with the necessary information, including a valid API key, as described below.
2. Copy the 1,029 preprocessed text files that make up the source text into the corresponding /OCM-papers/ directory. These files can be obtained by running the scripts and following the instructions included in the [/download_papers/large_database/](https://github.com/benjww/text_mining_prep/tree/main/download_papers/large_database/) and [/preprocessing/large_database/](https://github.com/benjww/text_mining_prep/tree/main/preprocessing/large_database/) directories in our sibling [text_mining_prep repository](https://github.com/benjww/text_mining_prep/tree/main/). We cannot upload them for copyright purposes. 

Llama 3.1 405B is employed across both of these tests. It is called using the Amazon Bedrock service provided by Amazon Web Services. Documentation for this cloud service can be found [here](https://docs.aws.amazon.com/bedrock/). In the provided api.env files you must enter your desired model ID, AWS Region, and two confidential API keys that can be requested upon creation of an AWS account. Model IDs and supported AWS Regions can be found [here](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html). 
